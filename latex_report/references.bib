@inproceedings{huang2022audiomae,
  title        = {Masked Autoencoders that Listen},
  author       = {Huang, Po-Yao and Xu, Hu and Li, Juncheng and Baevski, Alexei and Auli, Michael and Galuba, Wojciech and Metze, Florian and Feichtenhofer, Christoph},
  booktitle    = {Advances in Neural Information Processing Systems},
  year         = {2022}
}

@inproceedings{gong2021ast,
  title        = {AST: Audio Spectrogram Transformer},
  author       = {Gong, Yuan and Chung, Yu-An and Glass, James},
  booktitle    = {Interspeech},
  year         = {2021}
}

@inproceedings{chen2022beats,
  title        = {BEATs: Audio Pre-Training with Acoustic Tokenizers},
  author       = {Chen, Si and Peng, Bo and Wu, Jian and Chen, Gong},
  booktitle    = {International Conference on Learning Representations},
  year         = {2022}
}

@inproceedings{dosovitskiy2020vit,
  title        = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author       = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  booktitle    = {International Conference on Learning Representations},
  year         = {2020}
}

@article{benammar2025serenesense,
  title        = {SereneSense: Military Vehicle Sound Detection using Transformer Architectures},
  author       = {Ben Ammar, Sirine},
  journal      = {Technical Report},
  year         = {2025},
  note         = {AudioMAE atteint 82.15\% de précision de validation sur le dataset MAD}
}

@misc{mad_dataset,
  title        = {Military Audio Detection Dataset},
  author       = {{MAD Consortium}},
  year         = {2024},
  note         = {7 classes, 7,466 échantillons, 10 s @ 16 kHz}
}

@online{onnxruntime,
  title        = {ONNX Runtime Documentation},
  author       = {{ONNX Runtime Team}},
  year         = {2024},
  url          = {https://onnxruntime.ai},
  note         = {Guide officiel pour l'exécution ONNX sur CPU/ARM}
}

@online{esc50_dataset,
  title        = {ESC-50: Dataset for Environmental Sound Classification},
  author       = {Piczak, Karol J.},
  year         = {2015},
  url          = {https://github.com/karoldvl/ESC-50},
  note         = {Jeu de données de sons environnementaux largement utilisé comme benchmark}
}

@online{urbansound8k_dataset,
  title        = {UrbanSound8K: Dataset for Urban Sound Classification},
  author       = {Salamon, Justin},
  year         = {2014},
  url          = {https://urbansounddataset.weebly.com/urbansound8k.html},
  note         = {Jeu de données de sons urbains pour l'évaluation de classificateurs audio}
}

@article{kim2024mad,
  title        = {A Military Audio Dataset for Situational Awareness and Surveillance},
  author       = {Kim, Jae-Woo and Yoon, Chan and Jung, Hyun-Yong},
  journal      = {Scientific Data},
  volume       = {11},
  number       = {668},
  year         = {2024}
}

@inproceedings{gemmeke2017audioset,
  title        = {AudioSet: An Ontology and Human-Labeled Dataset for Audio Events},
  author       = {Gemmeke, Jort F. and Ellis, Daniel P. W. and Freedman, Dylan and Jansen, Aren and Lawrence, Wade and Moore, R. Channing and Plakal, Manoj and Ritter, Marvin and Saurous, Rif A. and Slaney, Malcolm and others},
  booktitle    = {Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year         = {2017}
}

% TODO: Compléter ce fichier avec les nombreuses autres sources listées dans data/sources.md.
