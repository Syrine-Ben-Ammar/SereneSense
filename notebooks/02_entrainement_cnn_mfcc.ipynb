{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2 : Entra√Ænement du Mod√®le CNN-MFCC\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Table des Mati√®res\n",
    "\n",
    "1. [Introduction et Contexte](#1-introduction)\n",
    "2. [Architecture du Mod√®le CNN-MFCC](#2-architecture)\n",
    "3. [Configuration d'Entra√Ænement](#3-configuration)\n",
    "4. [Processus d'Entra√Ænement](#4-entrainement)\n",
    "5. [R√©sultats et M√©triques](#5-resultats)\n",
    "6. [Visualisations et Analyses](#6-visualisations)\n",
    "7. [Analyse des Performances Par Classe](#7-analyse-classe)\n",
    "8. [Conclusion](#8-conclusion)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction et Contexte {#1-introduction}\n",
    "\n",
    "### Objectif\n",
    "\n",
    "Ce notebook documente l'entra√Ænement du mod√®le **CNN-MFCC** (Convolutional Neural Network with MFCC features), qui sert de **baseline** pour le projet SereneSense.\n",
    "\n",
    "### Mod√®le CNN-MFCC\n",
    "\n",
    "Le CNN-MFCC est un mod√®le de classification audio qui :\n",
    "- Utilise des **MFCC (Mel-Frequency Cepstral Coefficients)** comme features d'entr√©e\n",
    "- Applique une architecture **CNN √† 3 couches convolutives**\n",
    "- Classifie les sons en **7 cat√©gories** de v√©hicules militaires\n",
    "\n",
    "### R√©sultats Attendus\n",
    "\n",
    "D'apr√®s l'analyse du projet :\n",
    "- **Best Validation Accuracy** : 66.88% (epoch 29)\n",
    "- **Final Validation Accuracy** : 57.95% (epoch 150)\n",
    "- **Nombre de param√®tres** : 242,000 (242K)\n",
    "- **Temps d'entra√Ænement** : 2-3 heures sur GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des biblioth√®ques n√©cessaires\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import yaml\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Chemins du projet\n",
    "PROJECT_ROOT = Path(r'c:\\Users\\MDN\\Desktop\\SereneSense')\n",
    "sys.path.insert(0, str(PROJECT_ROOT / 'src'))\n",
    "\n",
    "CONFIG_PATH = PROJECT_ROOT / 'configs' / 'models' / 'legacy_cnn_mfcc.yaml'\n",
    "HISTORY_PATH = PROJECT_ROOT / 'outputs' / 'history' / 'cnn_baseline.json'\n",
    "OUTPUT_DIR = PROJECT_ROOT / 'outputs' / 'training_cnn'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Biblioth√®ques import√©es avec succ√®s\")\n",
    "print(f\"üìÅ Projet : {PROJECT_ROOT}\")\n",
    "print(f\"üîß PyTorch version : {torch.__version__}\")\n",
    "print(f\"üéÆ CUDA disponible : {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU : {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Architecture du Mod√®le CNN-MFCC {#2-architecture}\n",
    "\n",
    "### Structure du Mod√®le\n",
    "\n",
    "Le mod√®le CNN-MFCC est compos√© de :\n",
    "\n",
    "```\n",
    "Input: (batch, 3, 40, 92)\n",
    "  ‚Üì\n",
    "Conv2D(48, kernel=3√ó3) ‚Üí BatchNorm ‚Üí ReLU ‚Üí MaxPool(2√ó2) ‚Üí Dropout(0.25)\n",
    "  ‚Üì\n",
    "Conv2D(96, kernel=3√ó3) ‚Üí BatchNorm ‚Üí ReLU ‚Üí MaxPool(2√ó2) ‚Üí Dropout(0.30)\n",
    "  ‚Üì\n",
    "Conv2D(192, kernel=3√ó3) ‚Üí BatchNorm ‚Üí ReLU ‚Üí MaxPool(2√ó2) ‚Üí Dropout(0.30)\n",
    "  ‚Üì\n",
    "GlobalAveragePooling2D ‚Üí (192 features)\n",
    "  ‚Üì\n",
    "Dense(160) ‚Üí ReLU ‚Üí Dropout(0.35)\n",
    "  ‚Üì\n",
    "Dense(7) ‚Üí Softmax\n",
    "```\n",
    "\n",
    "### Features d'Entr√©e : MFCC\n",
    "\n",
    "- **Shape** : (3, 40, 92)\n",
    "- **Canaux** : 3 (MFCC + Delta + Delta-Delta)\n",
    "- **Coefficients MFCC** : 40\n",
    "- **Frames temporelles** : 92 (pour 3 secondes d'audio)\n",
    "- **Audio duration** : 3.0 secondes\n",
    "- **Hop length** : 512 samples (31.25ms)\n",
    "\n",
    "### Param√®tres Totaux : 242,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement de la configuration\n",
    "print(\"üìÑ Chargement de la configuration CNN-MFCC...\\n\")\n",
    "\n",
    "if CONFIG_PATH.exists():\n",
    "    with open(CONFIG_PATH, 'r', encoding='utf-8') as f:\n",
    "        cnn_config = yaml.safe_load(f)\n",
    "    \n",
    "    print(\"üîß Configuration MFCC :\")\n",
    "    mfcc_cfg = cnn_config.get('mfcc', {})\n",
    "    for key, value in mfcc_cfg.items():\n",
    "        print(f\"   ‚Ä¢ {key:20s} : {value}\")\n",
    "    \n",
    "    print(\"\\nüèóÔ∏è Architecture CNN :\")\n",
    "    cnn_arch = cnn_config.get('cnn', {})\n",
    "    for key, value in cnn_arch.items():\n",
    "        print(f\"   ‚Ä¢ {key:20s} : {value}\")\n",
    "    \n",
    "    print(\"\\nüé® SpecAugment :\")\n",
    "    spec_aug = cnn_config.get('spec_augment', {})\n",
    "    for key, value in spec_aug.items():\n",
    "        print(f\"   ‚Ä¢ {key:20s} : {value}\")\nelse:\n",
    "    print(f\"‚ö†Ô∏è Configuration non trouv√©e : {CONFIG_PATH}\")\n",
    "    cnn_config = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finition du mod√®le CNN-MFCC (architecture exacte du projet)\n",
    "class CNNMFCCModel(nn.Module):\n",
    "    \"\"\"Mod√®le CNN-MFCC pour classification audio.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=7, input_channels=3):\n",
    "        super(CNNMFCCModel, self).__init__()\n",
    "        \n",
    "        # Bloc Conv 1\n",
    "        self.conv1 = nn.Conv2d(input_channels, 48, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(48)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        \n",
    "        # Bloc Conv 2\n",
    "        self.conv2 = nn.Conv2d(48, 96, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(96)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout2 = nn.Dropout(0.30)\n",
    "        \n",
    "        # Bloc Conv 3\n",
    "        self.conv3 = nn.Conv2d(96, 192, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(192)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout3 = nn.Dropout(0.30)\n",
    "        \n",
    "        # Global Average Pooling\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # Fully Connected\n",
    "        self.fc1 = nn.Linear(192, 160)\n",
    "        self.dropout4 = nn.Dropout(0.35)\n",
    "        self.fc2 = nn.Linear(160, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Conv Block 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        # Conv Block 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        # Conv Block 3\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        # Global Average Pooling\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully Connected\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout4(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Instanciation du mod√®le\n",
    "model = CNNMFCCModel(num_classes=7, input_channels=3)\n",
    "\n",
    "# Comptage des param√®tres\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"\\nüéØ Mod√®le CNN-MFCC instanci√© :\")\n",
    "print(f\"   ‚Ä¢ Param√®tres totaux      : {total_params:,}\")\n",
    "print(f\"   ‚Ä¢ Param√®tres entra√Ænables : {trainable_params:,}\")\n",
    "print(f\"   ‚Ä¢ Taille du mod√®le        : {total_params * 4 / 1024 / 1024:.2f} MB (FP32)\")\n",
    "\n",
    "# Afficher l'architecture\n",
    "print(\"\\nüìê Architecture du mod√®le :\\n\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de la forme de sortie\n",
    "print(\"üß™ Test de la forme de sortie du mod√®le :\\n\")\n",
    "\n",
    "# Cr√©er un batch d'entr√©e fictif\n",
    "batch_size = 4\n",
    "dummy_input = torch.randn(batch_size, 3, 40, 92)\n",
    "\n",
    "print(f\"   Input shape  : {dummy_input.shape}\")\n",
    "\n",
    "# Forward pass\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(dummy_input)\n",
    "\n",
    "print(f\"   Output shape : {output.shape}\")\n",
    "print(f\"   Expected     : (batch_size={batch_size}, num_classes=7)\")\n",
    "print(f\"\\n‚úÖ Test r√©ussi !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Configuration d'Entra√Ænement {#3-configuration}\n",
    "\n",
    "### Hyperparam√®tres d'Entra√Ænement\n",
    "\n",
    "D'apr√®s le fichier `legacy_cnn_mfcc.yaml` et les r√©sultats obtenus :\n",
    "\n",
    "**Optimizer** :\n",
    "- Type : Adam\n",
    "- Learning Rate : 1e-3 (0.001)\n",
    "- Weight Decay : 0.0\n",
    "- Betas : (0.9, 0.999)\n",
    "\n",
    "**Training** :\n",
    "- Batch Size : 32\n",
    "- Epochs : 150\n",
    "- Loss Function : CrossEntropyLoss (avec class weights)\n",
    "\n",
    "**Learning Rate Schedule** :\n",
    "- Type : ReduceLROnPlateau\n",
    "- Factor : 0.5 (r√©duction de moiti√©)\n",
    "- Patience : 10 epochs\n",
    "- Min LR : 1e-7\n",
    "\n",
    "**Data Augmentation (SpecAugment)** :\n",
    "- Frequency Masking : 15% (2 masks)\n",
    "- Time Masking : 10% (2 masks)\n",
    "- Probability : 0.8\n",
    "\n",
    "### Commande d'Entra√Ænement\n",
    "\n",
    "```bash\n",
    "python scripts/train_legacy_model.py \\\n",
    "    --model cnn \\\n",
    "    --config configs/models/legacy_cnn_mfcc.yaml \\\n",
    "    --epochs 150 \\\n",
    "    --batch-size 32 \\\n",
    "    --learning-rate 1e-3 \\\n",
    "    --checkpoint outputs/phase1/cnn_baseline.pth\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration d'entra√Ænement (pour r√©f√©rence)\n",
    "training_config = {\n",
    "    'model': 'CNN-MFCC',\n",
    "    'optimizer': 'Adam',\n",
    "    'learning_rate': 1e-3,\n",
    "    'weight_decay': 0.0,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 150,\n",
    "    'loss_function': 'CrossEntropyLoss',\n",
    "    'lr_scheduler': 'ReduceLROnPlateau',\n",
    "    'lr_factor': 0.5,\n",
    "    'lr_patience': 10,\n",
    "    'num_classes': 7,\n",
    "    'input_shape': (3, 40, 92),\n",
    "    'audio_duration': 3.0,\n",
    "    'sample_rate': 16000,\n",
    "}\n",
    "\n",
    "print(\"‚öôÔ∏è Configuration d'entra√Ænement CNN-MFCC :\\n\")\n",
    "for key, value in training_config.items():\n",
    "    print(f\"   ‚Ä¢ {key:20s} : {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Processus d'Entra√Ænement {#4-entrainement}\n",
    "\n",
    "### D√©tails du Training\n",
    "\n",
    "L'entra√Ænement a √©t√© effectu√© sur **150 epochs** avec les observations suivantes :\n",
    "\n",
    "**Convergence** :\n",
    "- **Meilleure epoch** : 29\n",
    "- **Best Val Accuracy** : 66.88%\n",
    "- **Best Val Loss** : ~1.0\n",
    "\n",
    "**Probl√®mes observ√©s** :\n",
    "- **Overfitting** apr√®s l'epoch 29\n",
    "- Val Accuracy diminue √† 57.95% (epoch 150)\n",
    "- Val Loss augmente √† 1.3161\n",
    "\n",
    "**Learning Rate Schedule** :\n",
    "- Epochs 1-26 : LR = 1e-3\n",
    "- Epochs 27-40 : LR = 5e-4\n",
    "- Epochs 41-51 : LR = 2.5e-4\n",
    "- Continues jusqu'√† LR ‚âà 4.88e-7\n",
    "\n",
    "### Temps d'Entra√Ænement\n",
    "\n",
    "- **Total** : 2-3 heures sur GPU\n",
    "- **Par epoch** : ~1-1.5 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. R√©sultats et M√©triques {#5-resultats}\n",
    "\n",
    "### Chargement de l'Historique d'Entra√Ænement\n",
    "\n",
    "Les r√©sultats d'entra√Ænement sont sauvegard√©s dans `outputs/history/cnn_baseline.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement de l'historique d'entra√Ænement\n",
    "print(\"üìä Chargement de l'historique d'entra√Ænement...\\n\")\n",
    "\n",
    "if HISTORY_PATH.exists():\n",
    "    with open(HISTORY_PATH, 'r') as f:\n",
    "        history = json.load(f)\n",
    "    \n",
    "    print(\"‚úÖ Historique charg√© avec succ√®s !\\n\")\n",
    "    print(f\"üìà R√©sum√© des r√©sultats :\")\n",
    "    print(f\"   ‚Ä¢ Mod√®le              : {history.get('model')}\")\n",
    "    print(f\"   ‚Ä¢ Epochs demand√©es    : {history.get('epochs_requested')}\")\n",
    "    print(f\"   ‚Ä¢ Epochs compl√©t√©es   : {len(history.get('train_loss', []))}\")\n",
    "    print(f\"   ‚Ä¢ Best Val Accuracy   : {history.get('best_accuracy', 0)*100:.2f}%\")\n",
    "    print(f\"   ‚Ä¢ Best Epoch          : {history.get('best_epoch')}\")\n",
    "    print(f\"   ‚Ä¢ Final Train Loss    : {history['train_loss'][-1]:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Final Val Loss      : {history['val_loss'][-1]:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Final Val Accuracy  : {history['val_accuracy'][-1]*100:.2f}%\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Historique non trouv√© : {HISTORY_PATH}\")\n",
    "    print(\"   Utilisation de donn√©es simul√©es bas√©es sur les r√©sultats connus...\\n\")\n",
    "    \n",
    "    # Simulation bas√©e sur les r√©sultats r√©els\n",
    "    history = {\n",
    "        'model': 'CNN-MFCC',\n",
    "        'epochs_requested': 150,\n",
    "        'best_accuracy': 0.6688,\n",
    "        'best_epoch': 29,\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'val_accuracy': []\n",
    "    }\n",
    "    \n",
    "    # Simulation des courbes\n",
    "    for epoch in range(150):\n",
    "        if epoch < 29:\n",
    "            # Phase d'am√©lioration\n",
    "            train_loss = 2.0 - (epoch / 29) * 1.2\n",
    "            val_loss = 1.8 - (epoch / 29) * 0.8\n",
    "            val_acc = 0.2 + (epoch / 29) * 0.4688\n",
    "        else:\n",
    "            # Phase d'overfitting\n",
    "            train_loss = 0.8 - ((epoch - 29) / 121) * 0.0348\n",
    "            val_loss = 1.0 + ((epoch - 29) / 121) * 0.3161\n",
    "            val_acc = 0.6688 - ((epoch - 29) / 121) * 0.0893\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_accuracy'].append(val_acc)\n",
    "    \n",
    "    print(\"‚úÖ Donn√©es simul√©es cr√©√©es !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des m√©triques\n",
    "train_loss = np.array(history['train_loss'])\n",
    "val_loss = np.array(history['val_loss'])\n",
    "val_accuracy = np.array(history['val_accuracy'])\n",
    "epochs_range = np.arange(1, len(train_loss) + 1)\n",
    "\n",
    "best_epoch = history['best_epoch']\n",
    "best_acc = history['best_accuracy']\n",
    "\n",
    "print(f\"\\nüìä Statistiques d√©taill√©es :\\n\")\n",
    "print(f\"   Epoch {best_epoch:3d} (Meilleure) :\")\n",
    "print(f\"      Train Loss : {train_loss[best_epoch-1]:.4f}\")\n",
    "print(f\"      Val Loss   : {val_loss[best_epoch-1]:.4f}\")\n",
    "print(f\"      Val Acc    : {val_accuracy[best_epoch-1]*100:.2f}%\")\n",
    "print(f\"\\n   Epoch 150 (Finale) :\")\n",
    "print(f\"      Train Loss : {train_loss[-1]:.4f}\")\n",
    "print(f\"      Val Loss   : {val_loss[-1]:.4f}\")\n",
    "print(f\"      Val Acc    : {val_accuracy[-1]*100:.2f}%\")\n",
    "print(f\"\\n   üìâ D√©gradation apr√®s best epoch : {(best_acc - val_accuracy[-1])*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Visualisations et Analyses {#6-visualisations}\n",
    "\n",
    "### Courbes d'Entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des courbes d'entra√Ænement\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# 1. Loss curves\n",
    "axes[0, 0].plot(epochs_range, train_loss, label='Train Loss', color='steelblue', linewidth=2)\n",
    "axes[0, 0].plot(epochs_range, val_loss, label='Val Loss', color='darkorange', linewidth=2)\n",
    "axes[0, 0].axvline(x=best_epoch, color='red', linestyle='--', linewidth=1.5, \n",
    "                   label=f'Best Epoch ({best_epoch})')\n",
    "axes[0, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0, 0].set_title('Courbes de Loss (Train vs Validation)', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend(fontsize=10)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Validation Accuracy\n",
    "axes[0, 1].plot(epochs_range, val_accuracy * 100, color='forestgreen', linewidth=2)\n",
    "axes[0, 1].axvline(x=best_epoch, color='red', linestyle='--', linewidth=1.5,\n",
    "                   label=f'Best: {best_acc*100:.2f}%')\n",
    "axes[0, 1].axhline(y=best_acc*100, color='red', linestyle=':', linewidth=1, alpha=0.5)\n",
    "axes[0, 1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "axes[0, 1].set_title('Pr√©cision de Validation', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].legend(fontsize=10)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Loss zoom (premiers 50 epochs)\n",
    "axes[1, 0].plot(epochs_range[:50], train_loss[:50], label='Train Loss', \n",
    "                color='steelblue', linewidth=2)\n",
    "axes[1, 0].plot(epochs_range[:50], val_loss[:50], label='Val Loss', \n",
    "                color='darkorange', linewidth=2)\n",
    "axes[1, 0].axvline(x=best_epoch, color='red', linestyle='--', linewidth=1.5)\n",
    "axes[1, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Loss', fontsize=12)\n",
    "axes[1, 0].set_title('Zoom: 50 Premi√®res Epochs', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].legend(fontsize=10)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Overfitting analysis\n",
    "gap = val_loss - train_loss\n",
    "axes[1, 1].plot(epochs_range, gap, color='purple', linewidth=2)\n",
    "axes[1, 1].axhline(y=0, color='black', linestyle='-', linewidth=1, alpha=0.3)\n",
    "axes[1, 1].axvline(x=best_epoch, color='red', linestyle='--', linewidth=1.5,\n",
    "                   label='D√©but Overfitting')\n",
    "axes[1, 1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Val Loss - Train Loss', fontsize=12)\n",
    "axes[1, 1].set_title('Analyse de l\\'Overfitting', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].legend(fontsize=10)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'cnn_training_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"üíæ Graphique sauvegard√© : cnn_training_curves.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate Schedule (simulation)\n",
    "print(\"\\nüìâ √âvolution du Learning Rate (ReduceLROnPlateau) :\\n\")\n",
    "\n",
    "# Simulation du LR schedule bas√© sur patience=10\n",
    "lr_schedule = []\n",
    "current_lr = 1e-3\n",
    "plateau_counter = 0\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(150):\n",
    "    lr_schedule.append(current_lr)\n",
    "    \n",
    "    # V√©rifier si am√©lioration\n",
    "    if val_loss[epoch] < best_val_loss:\n",
    "        best_val_loss = val_loss[epoch]\n",
    "        plateau_counter = 0\n",
    "    else:\n",
    "        plateau_counter += 1\n",
    "    \n",
    "    # R√©duire LR si plateau\n",
    "    if plateau_counter >= 10:\n",
    "        current_lr *= 0.5\n",
    "        plateau_counter = 0\n",
    "        print(f\"   Epoch {epoch+1:3d} : LR r√©duit √† {current_lr:.2e}\")\n",
    "\n",
    "# Visualisation\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(epochs_range, lr_schedule, color='crimson', linewidth=2)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Learning Rate', fontsize=12)\n",
    "ax.set_title('√âvolution du Learning Rate (ReduceLROnPlateau)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_yscale('log')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'cnn_lr_schedule.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüíæ Graphique sauvegard√© : cnn_lr_schedule.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Analyse des Performances Par Classe {#7-analyse-classe}\n",
    "\n",
    "### R√©sultats Par Classe (Best Model - Epoch 29)\n",
    "\n",
    "D'apr√®s l'analyse du projet, voici les performances par classe :\n",
    "\n",
    "| Classe | Precision | Recall | F1-Score | Support |\n",
    "|--------|-----------|--------|----------|---------|\n",
    "| **Helicopter** | 0.82 | 0.93 | 0.87 | - |\n",
    "| **Fighter Aircraft** | 1.00 | 0.30 | 0.46 | - |\n",
    "| **Military Vehicle** | 0.52 | 0.50 | 0.51 | - |\n",
    "| **Truck** | 0.68 | 0.46 | 0.55 | - |\n",
    "| **Footsteps** | 0.60 | 0.35 | 0.45 | - |\n",
    "| **Speech** | 0.61 | 0.73 | 0.66 | - |\n",
    "| **Background** | 0.37 | 0.95 | 0.53 | - |\n",
    "\n",
    "**Moyennes pond√©r√©es** :\n",
    "- Precision : 0.69\n",
    "- Recall : 0.58\n",
    "- F1-Score : 0.57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finition des classes\n",
    "CLASS_NAMES = [\n",
    "    'Helicopter',\n",
    "    'Fighter Aircraft',\n",
    "    'Military Vehicle',\n",
    "    'Truck',\n",
    "    'Footsteps',\n",
    "    'Speech',\n",
    "    'Background'\n",
    "]\n",
    "\n",
    "# M√©triques par classe (r√©sultats r√©els du projet)\n",
    "class_metrics = {\n",
    "    'Class': CLASS_NAMES,\n",
    "    'Precision': [0.82, 1.00, 0.52, 0.68, 0.60, 0.61, 0.37],\n",
    "    'Recall': [0.93, 0.30, 0.50, 0.46, 0.35, 0.73, 0.95],\n",
    "    'F1-Score': [0.87, 0.46, 0.51, 0.55, 0.45, 0.66, 0.53]\n",
    "}\n",
    "\n",
    "df_metrics = pd.DataFrame(class_metrics)\n",
    "\n",
    "print(\"üìä Performances par Classe (Best Model - Epoch 29) :\\n\")\n",
    "print(df_metrics.to_string(index=False))\n",
    "\n",
    "print(f\"\\nüìà Moyennes pond√©r√©es :\")\n",
    "print(f\"   ‚Ä¢ Precision : 0.69\")\n",
    "print(f\"   ‚Ä¢ Recall    : 0.58\")\n",
    "print(f\"   ‚Ä¢ F1-Score  : 0.57\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des m√©triques par classe\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# 1. Barplot des m√©triques\n",
    "x = np.arange(len(CLASS_NAMES))\n",
    "width = 0.25\n",
    "\n",
    "axes[0].bar(x - width, df_metrics['Precision'], width, \n",
    "            label='Precision', color='steelblue', edgecolor='black')\n",
    "axes[0].bar(x, df_metrics['Recall'], width, \n",
    "            label='Recall', color='darkorange', edgecolor='black')\n",
    "axes[0].bar(x + width, df_metrics['F1-Score'], width, \n",
    "            label='F1-Score', color='forestgreen', edgecolor='black')\n",
    "\n",
    "axes[0].set_xlabel('Classe', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('M√©triques par Classe (CNN-MFCC)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(CLASS_NAMES, rotation=45, ha='right')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "axes[0].set_ylim([0, 1.05])\n",
    "\n",
    "# 2. Heatmap\n",
    "metrics_matrix = df_metrics[['Precision', 'Recall', 'F1-Score']].values.T\n",
    "im = axes[1].imshow(metrics_matrix, aspect='auto', cmap='RdYlGn', vmin=0, vmax=1)\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(CLASS_NAMES, rotation=45, ha='right')\n",
    "axes[1].set_yticks([0, 1, 2])\n",
    "axes[1].set_yticklabels(['Precision', 'Recall', 'F1-Score'])\n",
    "axes[1].set_title('Heatmap des M√©triques', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Ajouter les valeurs sur le heatmap\n",
    "for i in range(3):\n",
    "    for j in range(len(CLASS_NAMES)):\n",
    "        text = axes[1].text(j, i, f'{metrics_matrix[i, j]:.2f}',\n",
    "                           ha='center', va='center', color='black', fontweight='bold')\n",
    "\n",
    "fig.colorbar(im, ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'cnn_class_metrics.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"üíæ Graphique sauvegard√© : cnn_class_metrics.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion (simulation bas√©e sur les m√©triques)\n",
    "print(\"\\nüéØ Analyse des classes :\")\n",
    "print(\"\\n‚úÖ Classes bien classifi√©es :\")\n",
    "print(\"   ‚Ä¢ Helicopter (F1=0.87) : Meilleure performance\")\n",
    "print(\"   ‚Ä¢ Speech (F1=0.66) : Bonne reconnaissance\")\n",
    "print(\"\\n‚ö†Ô∏è Classes difficiles :\")\n",
    "print(\"   ‚Ä¢ Fighter Aircraft (F1=0.46) : Haute pr√©cision mais faible rappel\")\n",
    "print(\"   ‚Ä¢ Footsteps (F1=0.45) : Difficult√© de d√©tection\")\n",
    "print(\"   ‚Ä¢ Background (F1=0.53) : Confusion avec autres classes\")\n",
    "print(\"\\nüîÑ Confusions probables :\")\n",
    "print(\"   ‚Ä¢ Truck ‚Üî Military Vehicle\")\n",
    "print(\"   ‚Ä¢ Background ‚Üî Autres sons\")\n",
    "print(\"   ‚Ä¢ Fighter Aircraft confondu avec autres bruits a√©riens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Conclusion {#8-conclusion}\n",
    "\n",
    "### R√©sum√© des R√©sultats CNN-MFCC\n",
    "\n",
    "**‚úÖ Points Forts** :\n",
    "1. **Architecture l√©g√®re** : 242K param√®tres (~1 MB)\n",
    "2. **Convergence rapide** : Meilleure performance √† l'epoch 29\n",
    "3. **Accuracy respectable** : 66.88% sur validation\n",
    "4. **Classes bien reconnues** : Helicopter (87%), Speech (66%)\n",
    "5. **Entra√Ænement rapide** : 2-3 heures sur GPU\n",
    "\n",
    "**‚ö†Ô∏è Limitations** :\n",
    "1. **Overfitting s√©v√®re** : D√©gradation de 66.88% ‚Üí 57.95%\n",
    "2. **Classes difficiles** : Fighter (46%), Footsteps (45%)\n",
    "3. **Dur√©e audio courte** : Seulement 3 secondes\n",
    "4. **Features limit√©es** : MFCC seuls, pas de contexte temporel long\n",
    "\n",
    "### M√©triques Finales\n",
    "\n",
    "| M√©trique | Valeur |\n",
    "|----------|--------|\n",
    "| **Best Val Accuracy** | 66.88% (epoch 29) |\n",
    "| **Final Val Accuracy** | 57.95% (epoch 150) |\n",
    "| **Train Loss (final)** | 0.7652 |\n",
    "| **Val Loss (final)** | 1.3161 |\n",
    "| **Param√®tres** | 242,000 |\n",
    "| **Temps d'entra√Ænement** | 2-3 heures |\n",
    "| **F1-Score moyen** | 0.57 |\n",
    "\n",
    "### Am√©liorations Possibles\n",
    "\n",
    "1. **Early Stopping** : Arr√™ter √† l'epoch 29 pour √©viter l'overfitting\n",
    "2. **Plus de Regularization** : Augmenter dropout, weight decay\n",
    "3. **Data Augmentation** : Plus de vari√©t√© dans SpecAugment\n",
    "4. **Dur√©e audio** : Augmenter √† 4-5 secondes\n",
    "5. **Architecture** : Tester CRNN pour contexte temporel\n",
    "\n",
    "### Prochaines √âtapes\n",
    "\n",
    "Le **Notebook 3** explorera le mod√®le **CRNN-MFCC** qui am√©liore les r√©sultats √† **73.21%** gr√¢ce √† :\n",
    "- Mod√©lisation temporelle avec BiLSTM\n",
    "- Dur√©e audio de 4 secondes\n",
    "- Architecture plus profonde (1.5M param√®tres)\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: center; padding: 20px; background-color: #e8f4f8; border-radius: 10px;\">\n",
    "    <h3>üéâ Notebook 2 Compl√©t√© !</h3>\n",
    "    <p><b>CNN-MFCC : Baseline du Projet SereneSense</b></p>\n",
    "    <p>Accuracy : 66.88% | Param√®tres : 242K | Dur√©e : 3s</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
