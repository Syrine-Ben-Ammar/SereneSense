{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "cell-header",
            "metadata": {},
            "source": [
                "# Notebook 5 : D\u00e9ploiement sur Raspberry Pi 5\n",
                "\n",
                "**Projet SereneSense - D\u00e9tection de V\u00e9hicules Militaires par Analyse Audio**\n",
                "\n",
                "---\n",
                "\n",
                "## Introduction\n",
                "\n",
                "Ce cinqui\u00e8me et dernier notebook documente le **pipeline complet de d\u00e9ploiement** du mod\u00e8le AudioMAE sur **Raspberry Pi 5** pour la d\u00e9tection en temps r\u00e9el de v\u00e9hicules militaires.\n",
                "\n",
                "### Objectifs du Notebook\n",
                "\n",
                "1. **Export ONNX** : Conversion du mod\u00e8le PyTorch vers ONNX FP32\n",
                "2. **Quantification INT8** : Optimisation pour edge computing (r\u00e9duction 4\u00d7)\n",
                "3. **Validation du pipeline** : Tests sur PC avant d\u00e9ploiement\n",
                "4. **Scripts de d\u00e9ploiement** : Code pour Raspberry Pi 5\n",
                "5. **M\u00e9triques de performance** : Latence, m\u00e9moire, pr\u00e9cision sur RPi5\n",
                "\n",
                "### Architecture de D\u00e9ploiement\n",
                "\n",
                "```\n",
                "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
                "\u2502           PC de D\u00e9veloppement (Pr\u00e9-d\u00e9ploiement)         \u2502\n",
                "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
                "\u2502 1. Mod\u00e8le entra\u00een\u00e9 : checkpoint_audiomae_099.pth (424MB)\u2502\n",
                "\u2502 2. Export ONNX FP32 : export_to_onnx.py \u2192 424 MB        \u2502\n",
                "\u2502 3. Quantification INT8 : quantize_onnx.py \u2192 106 MB      \u2502\n",
                "\u2502 4. Validation : test_deployment.py                      \u2502\n",
                "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
                "                        \u2193 Transfert (scp)\n",
                "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
                "\u2502              Raspberry Pi 5 (D\u00e9ploiement)               \u2502\n",
                "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
                "\u2502 1. Setup : rpi_setup.sh (d\u00e9pendances)                   \u2502\n",
                "\u2502 2. Pr\u00e9traitement : rpi_preprocessing.py                 \u2502\n",
                "\u2502 3. Inf\u00e9rence ONNX : rpi_deploy.py                       \u2502\n",
                "\u2502 4. D\u00e9tection temps r\u00e9el : microphone USB \u2192 pr\u00e9dictions  \u2502\n",
                "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
                "```\n",
                "\n",
                "### R\u00e9sultats Cl\u00e9s du D\u00e9ploiement\n",
                "\n",
                "| M\u00e9trique | Valeur | Cible | Statut |\n",
                "|----------|--------|-------|--------|\n",
                "| **Pr\u00e9cision** | 82.15% | \u226580% | \u2705 Excellent |\n",
                "| **Latence d'inf\u00e9rence** | 240-280 ms | <500 ms | \u2705 Excellent |\n",
                "| **Latence totale** | 300-370 ms | <500 ms | \u2705 Excellent |\n",
                "| **Taille du mod\u00e8le** | 106 MB (INT8) | <200 MB | \u2705 Optimal |\n",
                "| **M\u00e9moire utilis\u00e9e** | ~800 MB | <2 GB | \u2705 Excellent |\n",
                "| **Consommation** | 8-12 W | <15 W | \u2705 Excellent |\n",
                "| **Temp\u00e9rature** | 45-55\u00b0C | <70\u00b0C | \u2705 Stable |\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "\"\"\"Initialisation et imports pour le notebook de d\u00e9ploiement.\"\"\"\n",
                "\n",
                "import os\n",
                "from pathlib import Path\n",
                "import json\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "\n",
                "# Configuration de matplotlib\n",
                "plt.style.use('seaborn-v0_8-darkgrid')\n",
                "plt.rcParams['figure.figsize'] = (12, 6)\n",
                "plt.rcParams['font.size'] = 10\n",
                "\n",
                "# Racine du projet\n",
                "PROJECT_ROOT = (Path.cwd() / \"..\").resolve()\n",
                "print(f\"Racine du projet : {PROJECT_ROOT}\")\n",
                "print(f\"Notebook : D\u00e9ploiement Raspberry Pi 5\")\n",
                "print(\"=\" * 70)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-phase1-title",
            "metadata": {},
            "source": [
                "## 1. Phase Pr\u00e9-D\u00e9ploiement (PC de D\u00e9veloppement)\n",
                "\n",
                "### 1.1 Export du Mod\u00e8le PyTorch vers ONNX\n",
                "\n",
                "Le script `scripts/export_to_onnx.py` convertit le mod\u00e8le PyTorch entra\u00een\u00e9 en format ONNX FP32 pour une compatibilit\u00e9 maximale avec ONNX Runtime.\n",
                "\n",
                "#### Pipeline d'Export\n",
                "\n",
                "```python\n",
                "# \u00c9tape 1 : Chargement du checkpoint PyTorch\n",
                "config = AudioMAEConfig(\n",
                "    num_classes=7,\n",
                "    img_size=(128, 128),\n",
                "    patch_size=16,\n",
                "    embed_dim=768,\n",
                "    encoder_depth=12,\n",
                "    encoder_num_heads=12\n",
                ")\n",
                "model = AudioMAE(config)\n",
                "checkpoint = torch.load('outputs/checkpoint_audiomae_099.pth')\n",
                "model.load_state_dict(checkpoint['state_dict'])\n",
                "model.eval()\n",
                "\n",
                "# \u00c9tape 2 : Export ONNX\n",
                "dummy_input = torch.randn(1, 1, 128, 128)  # Mel spectrogram\n",
                "torch.onnx.export(\n",
                "    model,\n",
                "    dummy_input,\n",
                "    'outputs/audiomae_fp32.onnx',\n",
                "    opset_version=14,\n",
                "    input_names=['spectrogram'],\n",
                "    output_names=['logits'],\n",
                "    dynamic_axes={'spectrogram': {0: 'batch_size'}}\n",
                ")\n",
                "\n",
                "# \u00c9tape 3 : Validation\n",
                "onnx_model = onnx.load('outputs/audiomae_fp32.onnx')\n",
                "onnx.checker.check_model(onnx_model)\n",
                "```\n",
                "\n",
                "#### Commande d'Ex\u00e9cution\n",
                "\n",
                "```bash\n",
                "cd SereneSense\n",
                "python scripts/export_to_onnx.py\n",
                "```\n",
                "\n",
                "#### R\u00e9sultats Attendus\n",
                "\n",
                "- **Fichier** : `outputs/audiomae_fp32.onnx`\n",
                "- **Taille** : 424 MB (111M param\u00e8tres FP32)\n",
                "- **Format** : ONNX opset 14\n",
                "- **Validation** : Output PyTorch \u2248 Output ONNX (diff\u00e9rence < 1e-5)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-onnx-sizes",
            "metadata": {},
            "outputs": [],
            "source": [
                "\"\"\"V\u00e9rification des fichiers ONNX export\u00e9s.\"\"\"\n",
                "\n",
                "onnx_fp32 = PROJECT_ROOT / \"outputs\" / \"audiomae_fp32.onnx\"\n",
                "onnx_int8 = PROJECT_ROOT / \"outputs\" / \"audiomae_int8.onnx\"\n",
                "\n",
                "def check_model_file(path: Path, label: str):\n",
                "    \"\"\"Affiche les informations d'un fichier mod\u00e8le.\"\"\"\n",
                "    if path.exists():\n",
                "        size_mb = path.stat().st_size / (1024 * 1024)\n",
                "        print(f\"\u2705 {label:20s} : {path.name:25s} \u2192 {size_mb:7.2f} MB\")\n",
                "        return size_mb\n",
                "    else:\n",
                "        print(f\"\u274c {label:20s} : Fichier non trouv\u00e9\")\n",
                "        return None\n",
                "\n",
                "print(\"\\n\ud83d\udce6 Fichiers ONNX G\u00e9n\u00e9r\u00e9s\")\n",
                "print(\"=\" * 70)\n",
                "fp32_size = check_model_file(onnx_fp32, \"ONNX FP32\")\n",
                "int8_size = check_model_file(onnx_int8, \"ONNX INT8\")\n",
                "\n",
                "if fp32_size and int8_size:\n",
                "    reduction = fp32_size / int8_size\n",
                "    percent = (1 - int8_size / fp32_size) * 100\n",
                "    print(\"\\n\ud83d\udcca R\u00e9duction de Taille\")\n",
                "    print(f\"  Facteur : {reduction:.2f}\u00d7 plus petit\")\n",
                "    print(f\"  Pourcentage : {percent:.1f}% de r\u00e9duction\")\n",
                "print(\"=\" * 70)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-quantization-title",
            "metadata": {},
            "source": [
                "### 1.2 Quantification INT8\n",
                "\n",
                "Le script `scripts/quantize_onnx.py` applique la **quantification dynamique INT8** pour optimiser le mod\u00e8le pour edge computing.\n",
                "\n",
                "#### Processus de Quantification\n",
                "\n",
                "```python\n",
                "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
                "\n",
                "quantize_dynamic(\n",
                "    model_input='outputs/audiomae_fp32.onnx',\n",
                "    model_output='outputs/audiomae_int8.onnx',\n",
                "    weight_type=QuantType.QInt8  # Poids en INT8\n",
                ")\n",
                "```\n",
                "\n",
                "#### Avantages de la Quantification INT8\n",
                "\n",
                "1. **R\u00e9duction de taille** : 424 MB \u2192 106 MB (4.0\u00d7 plus petit)\n",
                "2. **Acc\u00e9l\u00e9ration** : Inf\u00e9rence 2-3\u00d7 plus rapide sur CPU ARM\n",
                "3. **\u00c9conomie m\u00e9moire** : ~800 MB vs ~1.5 GB (FP32)\n",
                "4. **Perte de pr\u00e9cision** : <0.3% (82.15% \u2192 ~81.87%)\n",
                "\n",
                "#### Commande d'Ex\u00e9cution\n",
                "\n",
                "```bash\n",
                "python scripts/quantize_onnx.py\n",
                "```\n",
                "\n",
                "#### Validation de la Quantification\n",
                "\n",
                "Le script compare automatiquement :\n",
                "- **Tailles** : FP32 vs INT8\n",
                "- **Vitesse d'inf\u00e9rence** : Benchmark sur 100 \u00e9chantillons\n",
                "- **Accord de pr\u00e9dictions** : FP32 vs INT8 sur 200 \u00e9chantillons al\u00e9atoires\n",
                "\n",
                "**R\u00e9sultats typiques** :\n",
                "- Accord de pr\u00e9dictions : >98% (197/200)\n",
                "- Diff\u00e9rence moyenne des logits : <0.05\n",
                "- Speedup sur ARM64 : 2.2\u00d7 plus rapide\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-quantization-viz",
            "metadata": {},
            "outputs": [],
            "source": [
                "\"\"\"Visualisation de la comparaison FP32 vs INT8.\"\"\"\n",
                "\n",
                "# Donn\u00e9es de performance (d'apr\u00e8s DEPLOYMENT_SUMMARY.md)\n",
                "comparison_data = {\n",
                "    'Format': ['PyTorch FP32', 'ONNX FP32', 'ONNX INT8'],\n",
                "    'Taille (MB)': [424, 424, 106],\n",
                "    'Latence RPi5 (ms)': [np.nan, 520, 260],\n",
                "    'Pr\u00e9cision (%)': [82.15, 82.15, 81.87]\n",
                "}\n",
                "\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
                "\n",
                "# Graphique 1 : Taille du mod\u00e8le\n",
                "axes[0].bar(comparison_data['Format'], comparison_data['Taille (MB)'],\n",
                "            color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
                "axes[0].set_ylabel('Taille (MB)', fontsize=11, fontweight='bold')\n",
                "axes[0].set_title('Taille du Mod\u00e8le', fontsize=12, fontweight='bold')\n",
                "axes[0].tick_params(axis='x', rotation=15)\n",
                "for i, v in enumerate(comparison_data['Taille (MB)']):\n",
                "    axes[0].text(i, v + 10, f\"{v} MB\", ha='center', fontsize=9, fontweight='bold')\n",
                "\n",
                "# Graphique 2 : Latence d'inf\u00e9rence\n",
                "latencies = [comparison_data['Latence RPi5 (ms)'][i] for i in [1, 2]]\n",
                "axes[1].bar(['ONNX FP32', 'ONNX INT8'], latencies,\n",
                "            color=['#ff7f0e', '#2ca02c'])\n",
                "axes[1].set_ylabel('Latence (ms)', fontsize=11, fontweight='bold')\n",
                "axes[1].set_title('Latence sur Raspberry Pi 5', fontsize=12, fontweight='bold')\n",
                "axes[1].axhline(y=500, color='r', linestyle='--', linewidth=1.5, label='Cible (<500ms)')\n",
                "axes[1].legend()\n",
                "for i, v in enumerate(latencies):\n",
                "    axes[1].text(i, v + 15, f\"{v:.0f} ms\", ha='center', fontsize=9, fontweight='bold')\n",
                "\n",
                "# Graphique 3 : Pr\u00e9cision\n",
                "axes[2].bar(comparison_data['Format'], comparison_data['Pr\u00e9cision (%)'],\n",
                "            color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
                "axes[2].set_ylabel('Pr\u00e9cision (%)', fontsize=11, fontweight='bold')\n",
                "axes[2].set_title('Pr\u00e9cision du Mod\u00e8le', fontsize=12, fontweight='bold')\n",
                "axes[2].set_ylim([75, 85])\n",
                "axes[2].axhline(y=80, color='r', linestyle='--', linewidth=1.5, label='Cible (\u226580%)')\n",
                "axes[2].legend()\n",
                "axes[2].tick_params(axis='x', rotation=15)\n",
                "for i, v in enumerate(comparison_data['Pr\u00e9cision (%)']):\n",
                "    axes[2].text(i, v + 0.3, f\"{v:.2f}%\", ha='center', fontsize=9, fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.suptitle('Comparaison FP32 vs INT8 - Optimisation pour Raspberry Pi 5',\n",
                "             fontsize=14, fontweight='bold', y=1.02)\n",
                "plt.show()\n",
                "\n",
                "print(\"\\n\ud83d\udcca R\u00e9sum\u00e9 de l'Optimisation INT8\")\n",
                "print(\"=\" * 70)\n",
                "print(f\"\u2705 R\u00e9duction de taille : 424 MB \u2192 106 MB (4.0\u00d7 plus petit)\")\n",
                "print(f\"\u2705 Acc\u00e9l\u00e9ration : 520 ms \u2192 260 ms (2.0\u00d7 plus rapide)\")\n",
                "print(f\"\u2705 Perte de pr\u00e9cision : 82.15% \u2192 81.87% (seulement -0.28%)\")\n",
                "print(f\"\u2705 Respect des cibles : Latence <500ms \u2713, Pr\u00e9cision \u226580% \u2713\")\n",
                "print(\"=\" * 70)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-validation-title",
            "metadata": {},
            "source": [
                "### 1.3 Validation du Pipeline (PC)\n",
                "\n",
                "Le script `scripts/test_deployment.py` valide le pipeline complet avant transfert sur Raspberry Pi.\n",
                "\n",
                "#### Tests Effectu\u00e9s\n",
                "\n",
                "1. **Test 1 : Chargement du mod\u00e8le**\n",
                "   ```python\n",
                "   session = ort.InferenceSession('outputs/audiomae_int8.onnx')\n",
                "   # V\u00e9rifie : providers, input/output names, shapes\n",
                "   ```\n",
                "\n",
                "2. **Test 2 : Pipeline de pr\u00e9traitement**\n",
                "   ```python\n",
                "   preprocessor = AudioPreprocessor()\n",
                "   dummy_audio = np.random.randn(16000 * 10)\n",
                "   spectrogram = preprocessor.preprocess((dummy_audio, 16000), input_type='array')\n",
                "   assert spectrogram.shape == (1, 1, 128, 128)\n",
                "   ```\n",
                "\n",
                "3. **Test 3 : Inf\u00e9rence**\n",
                "   ```python\n",
                "   output = session.run(None, {'spectrogram': spectrogram})[0]\n",
                "   assert output.shape == (1, 7)  # 7 classes\n",
                "   ```\n",
                "\n",
                "4. **Test 4 : Mesure de latence**\n",
                "   - Pr\u00e9traitement : 60-90 ms\n",
                "   - Inf\u00e9rence : 240-280 ms (RPi5) / 50-100 ms (PC GPU)\n",
                "   - Total : <500 ms \u2705\n",
                "\n",
                "5. **Test 5 : Utilisation m\u00e9moire**\n",
                "   - Mod\u00e8le charg\u00e9 : ~106 MB\n",
                "   - Buffers : ~100 MB\n",
                "   - Estimation totale : ~800 MB\n",
                "\n",
                "#### Commande d'Ex\u00e9cution\n",
                "\n",
                "```bash\n",
                "python scripts/test_deployment.py\n",
                "```\n",
                "\n",
                "**Note** : Sur PC x86/x64, seul le mod\u00e8le FP32 sera test\u00e9 (INT8 n\u00e9cessite ARM64).\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-preprocessing-title",
            "metadata": {},
            "source": [
                "## 2. Module de Pr\u00e9traitement Raspberry Pi\n",
                "\n",
                "### 2.1 Script `rpi_preprocessing.py`\n",
                "\n",
                "Ce module impl\u00e9mente le pipeline de pr\u00e9traitement audio optimis\u00e9 pour Raspberry Pi, **identique** \u00e0 celui utilis\u00e9 pendant l'entra\u00eenement.\n",
                "\n",
                "#### Classe `AudioPreprocessor`\n",
                "\n",
                "```python\n",
                "class AudioPreprocessor:\n",
                "    def __init__(\n",
                "        self,\n",
                "        sample_rate: int = 16000,\n",
                "        duration: float = 10.0,\n",
                "        n_mels: int = 128,\n",
                "        n_fft: int = 1024,\n",
                "        hop_length: int = 160,\n",
                "        fmin: float = 50.0,\n",
                "        fmax: float = 8000.0\n",
                "    ):\n",
                "        self.sample_rate = sample_rate\n",
                "        self.duration = duration\n",
                "        self.expected_samples = int(sample_rate * duration)  # 160,000\n",
                "        # ... param\u00e8tres mel-spectrogram\n",
                "```\n",
                "\n",
                "#### Pipeline Complet\n",
                "\n",
                "```python\n",
                "def preprocess(self, audio_input, input_type='array'):\n",
                "    # \u00c9tape 1 : Chargement audio (fichier ou array)\n",
                "    if input_type == 'file':\n",
                "        audio = librosa.load(audio_input, sr=16000, mono=True, duration=10.0)\n",
                "    else:\n",
                "        audio, sr = audio_input\n",
                "        audio = librosa.resample(audio, orig_sr=sr, target_sr=16000)\n",
                "    \n",
                "    # \u00c9tape 2 : Ajustement longueur (pad/crop \u2192 10s)\n",
                "    audio = self._adjust_audio_length(audio)\n",
                "    \n",
                "    # \u00c9tape 3 : G\u00e9n\u00e9ration mel-spectrogram\n",
                "    mel_spec = librosa.feature.melspectrogram(\n",
                "        y=audio, sr=16000, n_fft=1024, hop_length=160,\n",
                "        n_mels=128, fmin=50, fmax=8000, power=2.0\n",
                "    )\n",
                "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
                "    \n",
                "    # \u00c9tape 4 : Resize vers 128\u00d7128\n",
                "    mel_spec = self.resize_spectrogram(mel_spec_db, target_size=(128, 128))\n",
                "    \n",
                "    # \u00c9tape 5 : Normalisation (ImageNet stats)\n",
                "    mel_spec = (mel_spec - mel_min) / (mel_max - mel_min)  # [0, 1]\n",
                "    mel_spec = (mel_spec - 0.485) / 0.229  # Standardisation\n",
                "    \n",
                "    # \u00c9tape 6 : Reshape pour ONNX\n",
                "    mel_spec = mel_spec[np.newaxis, np.newaxis, :, :]  # (1, 1, 128, 128)\n",
                "    return mel_spec.astype(np.float32)\n",
                "```\n",
                "\n",
                "#### Optimisations pour ARM\n",
                "\n",
                "- Utilisation de **librosa** (optimis\u00e9 pour CPU)\n",
                "- **scipy.ndimage.zoom** pour resize (plus rapide que PIL)\n",
                "- Pas de GPU (PyTorch non n\u00e9cessaire)\n",
                "- Latence : **60-90 ms** sur Raspberry Pi 5\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-deploy-title",
            "metadata": {},
            "source": [
                "## 3. Script de D\u00e9ploiement Raspberry Pi\n",
                "\n",
                "### 3.1 Script `rpi_deploy.py`\n",
                "\n",
                "Application principale de d\u00e9tection en temps r\u00e9el sur Raspberry Pi 5.\n",
                "\n",
                "#### Classe `MilitaryVehicleDetector`\n",
                "\n",
                "```python\n",
                "class MilitaryVehicleDetector:\n",
                "    CLASS_LABELS = [\n",
                "        \"Helicopter\",\n",
                "        \"Fighter Aircraft\",\n",
                "        \"Military Vehicle\",\n",
                "        \"Truck\",\n",
                "        \"Footsteps\",\n",
                "        \"Speech\",\n",
                "        \"Background\"\n",
                "    ]\n",
                "    \n",
                "    def __init__(self, model_path, sample_rate=16000, duration=10.0):\n",
                "        # Initialisation du pr\u00e9processeur\n",
                "        self.preprocessor = AudioPreprocessor(sample_rate, duration)\n",
                "        \n",
                "        # Chargement du mod\u00e8le ONNX\n",
                "        self.session = ort.InferenceSession(\n",
                "            model_path,\n",
                "            providers=['CPUExecutionProvider']\n",
                "        )\n",
                "```\n",
                "\n",
                "#### Capture Audio Temps R\u00e9el\n",
                "\n",
                "```python\n",
                "def capture_audio_realtime(self, duration=10.0):\n",
                "    \"\"\"Capture audio depuis microphone USB.\"\"\"\n",
                "    audio_interface = pyaudio.PyAudio()\n",
                "    stream = audio_interface.open(\n",
                "        format=pyaudio.paInt16,\n",
                "        channels=1,  # Mono\n",
                "        rate=16000,\n",
                "        input=True,\n",
                "        frames_per_buffer=1024\n",
                "    )\n",
                "    \n",
                "    # Enregistrement\n",
                "    frames = []\n",
                "    for _ in range(int(16000 / 1024 * duration)):\n",
                "        data = stream.read(1024)\n",
                "        frames.append(data)\n",
                "    \n",
                "    # Conversion en array numpy\n",
                "    audio = np.frombuffer(b''.join(frames), dtype=np.int16)\n",
                "    audio = audio.astype(np.float32) / 32768.0  # Normalisation [-1, 1]\n",
                "    \n",
                "    stream.stop_stream()\n",
                "    stream.close()\n",
                "    return audio\n",
                "```\n",
                "\n",
                "#### Inf\u00e9rence\n",
                "\n",
                "```python\n",
                "def predict(self, audio):\n",
                "    # Pr\u00e9traitement\n",
                "    spectrogram = self.preprocessor.preprocess(\n",
                "        (audio, 16000), input_type='array'\n",
                "    )\n",
                "    \n",
                "    # Inf\u00e9rence ONNX\n",
                "    start = time.time()\n",
                "    logits = self.session.run(None, {'spectrogram': spectrogram})[0]\n",
                "    inference_time = (time.time() - start) * 1000  # ms\n",
                "    \n",
                "    # Softmax \u2192 probabilit\u00e9s\n",
                "    probabilities = self.softmax(logits[0])\n",
                "    predicted_class = np.argmax(probabilities)\n",
                "    confidence = probabilities[predicted_class]\n",
                "    \n",
                "    return predicted_class, confidence, probabilities, inference_time\n",
                "```\n",
                "\n",
                "#### Boucle de D\u00e9tection Continue\n",
                "\n",
                "```python\n",
                "def run_continuous_detection(self, interval=10.0, max_detections=None, verbose=True):\n",
                "    detection_count = 0\n",
                "    \n",
                "    try:\n",
                "        while True:\n",
                "            # Capture audio\n",
                "            audio = self.capture_audio_realtime(duration=interval)\n",
                "            \n",
                "            # Pr\u00e9diction\n",
                "            pred_class, confidence, probs, inf_time = self.predict(audio)\n",
                "            class_name = self.CLASS_LABELS[pred_class]\n",
                "            \n",
                "            # Affichage\n",
                "            print(f\"Detection #{detection_count + 1}\")\n",
                "            print(f\"  Predicted: {class_name}\")\n",
                "            print(f\"  Confidence: {confidence:.2%}\")\n",
                "            print(f\"  Inference time: {inf_time:.1f} ms\")\n",
                "            \n",
                "            if verbose:\n",
                "                for i, (label, prob) in enumerate(zip(self.CLASS_LABELS, probs)):\n",
                "                    marker = \"\u2192\" if i == pred_class else \" \"\n",
                "                    print(f\"    {marker} {label:20s}: {prob:.2%}\")\n",
                "            \n",
                "            detection_count += 1\n",
                "            \n",
                "            if max_detections and detection_count >= max_detections:\n",
                "                break\n",
                "    \n",
                "    except KeyboardInterrupt:\n",
                "        print(f\"\\nDetection stopped. Total: {detection_count}\")\n",
                "```\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-usage-title",
            "metadata": {},
            "source": [
                "## 4. Utilisation sur Raspberry Pi 5\n",
                "\n",
                "### 4.1 Commandes d'Installation\n",
                "\n",
                "#### \u00c9tape 1 : Transfert des Fichiers\n",
                "\n",
                "Depuis le PC de d\u00e9veloppement :\n",
                "\n",
                "```bash\n",
                "# Cr\u00e9er le r\u00e9pertoire\n",
                "ssh pi@<raspberry_pi_ip> \"mkdir -p ~/serenity_deploy\"\n",
                "\n",
                "# Transf\u00e9rer les fichiers\n",
                "scp outputs/audiomae_int8.onnx pi@<ip>:~/serenity_deploy/\n",
                "scp scripts/rpi_preprocessing.py pi@<ip>:~/serenity_deploy/\n",
                "scp scripts/rpi_deploy.py pi@<ip>:~/serenity_deploy/\n",
                "scp scripts/rpi_requirements.txt pi@<ip>:~/serenity_deploy/\n",
                "scp scripts/rpi_setup.sh pi@<ip>:~/serenity_deploy/\n",
                "```\n",
                "\n",
                "#### \u00c9tape 2 : Setup Automatique\n",
                "\n",
                "Sur le Raspberry Pi (via SSH) :\n",
                "\n",
                "```bash\n",
                "cd ~/serenity_deploy\n",
                "chmod +x rpi_setup.sh\n",
                "bash rpi_setup.sh\n",
                "```\n",
                "\n",
                "Le script `rpi_setup.sh` effectue :\n",
                "- Mise \u00e0 jour syst\u00e8me (`apt update && apt upgrade`)\n",
                "- Installation d\u00e9pendances syst\u00e8me : `portaudio19-dev`, `libsndfile1`, `libatlas-base-dev`\n",
                "- Installation Python : `onnxruntime==1.16.0`, `librosa==0.10.1`, `pyaudio==0.2.14`, etc.\n",
                "- V\u00e9rification installation\n",
                "\n",
                "**Dur\u00e9e** : 15-20 minutes\n",
                "\n",
                "#### \u00c9tape 3 : Connexion Microphone USB\n",
                "\n",
                "```bash\n",
                "# V\u00e9rifier d\u00e9tection\n",
                "lsusb  # Doit afficher le p\u00e9riph\u00e9rique audio USB\n",
                "arecord -l  # Liste les p\u00e9riph\u00e9riques de capture\n",
                "\n",
                "# Test capture\n",
                "arecord -d 5 -f cd test.wav\n",
                "aplay test.wav\n",
                "```\n",
                "\n",
                "### 4.2 Modes de D\u00e9tection\n",
                "\n",
                "#### Mode 1 : D\u00e9tection Temps R\u00e9el (Basique)\n",
                "\n",
                "```bash\n",
                "python3 rpi_deploy.py --mode realtime\n",
                "```\n",
                "\n",
                "**Sortie attendue** :\n",
                "```\n",
                "[2025-11-21 14:30:10] Detection #1\n",
                "  Predicted: Helicopter\n",
                "  Confidence: 87.32%\n",
                "  Inference time: 243.5 ms\n",
                "```\n",
                "\n",
                "#### Mode 2 : D\u00e9tection Verbose (Probabilit\u00e9s Compl\u00e8tes)\n",
                "\n",
                "```bash\n",
                "python3 rpi_deploy.py --mode realtime --verbose --max-detections 10\n",
                "```\n",
                "\n",
                "**Sortie attendue** :\n",
                "```\n",
                "[2025-11-21 14:30:10] Detection #1\n",
                "  Predicted: Military Vehicle\n",
                "  Confidence: 92.15%\n",
                "  Inference time: 238.1 ms\n",
                "  All probabilities:\n",
                "    \u2192 Military Vehicle    : 92.15%\n",
                "      Truck              : 4.32%\n",
                "      Background         : 2.11%\n",
                "      Helicopter         : 0.89%\n",
                "      Fighter Aircraft   : 0.31%\n",
                "      Footsteps          : 0.18%\n",
                "      Speech             : 0.04%\n",
                "```\n",
                "\n",
                "#### Mode 3 : Test sur Fichier Audio\n",
                "\n",
                "```bash\n",
                "python3 rpi_deploy.py --mode file --file test_helicopter.wav\n",
                "```\n",
                "\n",
                "#### Mode 4 : Seuil de Confiance Personnalis\u00e9\n",
                "\n",
                "```bash\n",
                "# Haute pr\u00e9cision (peu de faux positifs)\n",
                "python3 rpi_deploy.py --mode realtime --confidence 0.8\n",
                "\n",
                "# Haute sensibilit\u00e9 (capture plus de d\u00e9tections)\n",
                "python3 rpi_deploy.py --mode realtime --confidence 0.4\n",
                "```\n",
                "\n",
                "### 4.3 Options Compl\u00e8tes\n",
                "\n",
                "```bash\n",
                "python3 rpi_deploy.py \\\n",
                "    --mode realtime \\\n",
                "    --model audiomae_int8.onnx \\\n",
                "    --interval 10 \\\n",
                "    --confidence 0.5 \\\n",
                "    --max-detections 100 \\\n",
                "    --verbose\n",
                "```\n",
                "\n",
                "| Option | Description | D\u00e9faut |\n",
                "|--------|-------------|--------|\n",
                "| `--mode` | `realtime` ou `file` | `realtime` |\n",
                "| `--model` | Chemin vers ONNX | `audiomae_int8.onnx` |\n",
                "| `--file` | Fichier audio (mode file) | - |\n",
                "| `--interval` | Intervalle d\u00e9tection (s) | 10.0 |\n",
                "| `--confidence` | Seuil de confiance | 0.5 |\n",
                "| `--max-detections` | Nombre max d\u00e9tections | Illimit\u00e9 |\n",
                "| `--verbose` | Afficher toutes les probabilit\u00e9s | False |\n",
                "| `--gpu` | Utiliser GPU si disponible | False |\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-performance-title",
            "metadata": {},
            "source": [
                "## 5. M\u00e9triques de Performance sur Raspberry Pi 5\n",
                "\n",
                "### 5.1 Configuration Mat\u00e9rielle Test\u00e9e\n",
                "\n",
                "| Composant | Sp\u00e9cification |\n",
                "|-----------|---------------|\n",
                "| **Mod\u00e8le** | Raspberry Pi 5 (8 GB RAM) |\n",
                "| **CPU** | ARM Cortex-A76 Quad-Core @ 2.4 GHz |\n",
                "| **Refroidissement** | Ventilateur actif |\n",
                "| **OS** | Raspberry Pi OS 64-bit Bookworm |\n",
                "| **Microphone** | USB g\u00e9n\u00e9rique 16 kHz |\n",
                "| **Alimentation** | 5V / 5A (27W) |\n",
                "\n",
                "### 5.2 R\u00e9sultats Mesur\u00e9s\n",
                "\n",
                "#### Latence (Temps de Traitement)\n",
                "\n",
                "| \u00c9tape | Temps (ms) | Pourcentage |\n",
                "|-------|------------|-------------|\n",
                "| **Capture audio** | 10,000 | (Fixe - 10s) |\n",
                "| **Pr\u00e9traitement** | 60-90 | 20% |\n",
                "| **Inf\u00e9rence ONNX INT8** | 240-280 | 75% |\n",
                "| **Post-traitement** | 1-5 | 1% |\n",
                "| **Total (hors capture)** | 300-370 | 100% |\n",
                "\n",
                "**\u2705 Cible respect\u00e9e : <500 ms**\n",
                "\n",
                "#### Utilisation Ressources\n",
                "\n",
                "| M\u00e9trique | Valeur | Cible | Statut |\n",
                "|----------|--------|-------|--------|\n",
                "| **M\u00e9moire RAM** | ~800 MB | <2 GB | \u2705 Excellent |\n",
                "| **CPU (1 c\u0153ur)** | 40-60% | - | \u2705 Stable |\n",
                "| **Temp\u00e9rature** | 45-55\u00b0C | <70\u00b0C | \u2705 Optimal |\n",
                "| **Consommation** | 8-12 W | <15 W | \u2705 Efficace |\n",
                "\n",
                "#### Pr\u00e9cision du Mod\u00e8le\n",
                "\n",
                "| Mod\u00e8le | Format | Pr\u00e9cision Val | Diff\u00e9rence |\n",
                "|--------|--------|---------------|------------|\n",
                "| AudioMAE (entra\u00eenement) | PyTorch FP32 | 82.15% | R\u00e9f\u00e9rence |\n",
                "| AudioMAE (d\u00e9ploiement) | ONNX INT8 | 81.87% | -0.28% |\n",
                "\n",
                "**\u2705 Perte minimale (<0.3%)**\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-performance-viz",
            "metadata": {},
            "outputs": [],
            "source": [
                "\"\"\"Visualisation des m\u00e9triques de performance Raspberry Pi 5.\"\"\"\n",
                "\n",
                "# Donn\u00e9es de latence\n",
                "latency_data = {\n",
                "    '\u00c9tape': ['Pr\u00e9traitement', 'Inf\u00e9rence INT8', 'Post-traitement'],\n",
                "    'Temps (ms)': [75, 260, 3],\n",
                "    'Couleur': ['#ff7f0e', '#2ca02c', '#d62728']\n",
                "}\n",
                "\n",
                "# Donn\u00e9es de comparaison PC vs RPi\n",
                "comparison = {\n",
                "    'Platform': ['PC GPU', 'PC CPU', 'RPi 5 INT8'],\n",
                "    'Latence (ms)': [65, 250, 260],\n",
                "    'M\u00e9moire (MB)': [2500, 1800, 800],\n",
                "    'Puissance (W)': [200, 80, 10]\n",
                "}\n",
                "\n",
                "fig = plt.figure(figsize=(16, 5))\n",
                "gs = fig.add_gridspec(1, 3, hspace=0.3, wspace=0.3)\n",
                "\n",
                "# Graphique 1 : D\u00e9composition latence\n",
                "ax1 = fig.add_subplot(gs[0, 0])\n",
                "wedges, texts, autotexts = ax1.pie(\n",
                "    latency_data['Temps (ms)'],\n",
                "    labels=latency_data['\u00c9tape'],\n",
                "    colors=latency_data['Couleur'],\n",
                "    autopct='%1.1f%%',\n",
                "    startangle=90,\n",
                "    textprops={'fontsize': 10, 'fontweight': 'bold'}\n",
                ")\n",
                "ax1.set_title('D\u00e9composition de la Latence Totale\\n(338 ms)', fontsize=12, fontweight='bold')\n",
                "\n",
                "# Graphique 2 : Comparaison latence PC vs RPi\n",
                "ax2 = fig.add_subplot(gs[0, 1])\n",
                "bars = ax2.barh(comparison['Platform'], comparison['Latence (ms)'],\n",
                "                color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
                "ax2.set_xlabel('Latence d\\'Inf\u00e9rence (ms)', fontsize=11, fontweight='bold')\n",
                "ax2.set_title('Comparaison Latence\\nPC vs Raspberry Pi 5', fontsize=12, fontweight='bold')\n",
                "ax2.axvline(x=500, color='r', linestyle='--', linewidth=1.5, label='Cible (<500ms)')\n",
                "ax2.legend()\n",
                "for i, v in enumerate(comparison['Latence (ms)']):\n",
                "    ax2.text(v + 10, i, f\"{v} ms\", va='center', fontsize=9, fontweight='bold')\n",
                "\n",
                "# Graphique 3 : Efficacit\u00e9 \u00e9nerg\u00e9tique\n",
                "ax3 = fig.add_subplot(gs[0, 2])\n",
                "x = np.arange(len(comparison['Platform']))\n",
                "width = 0.35\n",
                "bars1 = ax3.bar(x - width/2, comparison['M\u00e9moire (MB)'], width, label='M\u00e9moire (MB)',\n",
                "                color='#ff7f0e')\n",
                "bars2 = ax3.bar(x + width/2, [p * 10 for p in comparison['Puissance (W)']], width,\n",
                "                label='Puissance (W \u00d7 10)', color='#2ca02c')\n",
                "ax3.set_ylabel('Valeur', fontsize=11, fontweight='bold')\n",
                "ax3.set_title('Utilisation Ressources', fontsize=12, fontweight='bold')\n",
                "ax3.set_xticks(x)\n",
                "ax3.set_xticklabels(comparison['Platform'])\n",
                "ax3.legend()\n",
                "\n",
                "plt.suptitle('M\u00e9triques de Performance - Raspberry Pi 5',\n",
                "             fontsize=14, fontweight='bold', y=1.02)\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Tableau r\u00e9capitulatif\n",
                "print(\"\\n\ud83d\udcca Tableau R\u00e9capitulatif des Performances\")\n",
                "print(\"=\" * 70)\n",
                "perf_df = pd.DataFrame({\n",
                "    'M\u00e9trique': [\n",
                "        'Latence Pr\u00e9traitement',\n",
                "        'Latence Inf\u00e9rence',\n",
                "        'Latence Totale',\n",
                "        'M\u00e9moire RAM',\n",
                "        'CPU Usage',\n",
                "        'Temp\u00e9rature',\n",
                "        'Consommation',\n",
                "        'Pr\u00e9cision'\n",
                "    ],\n",
                "    'Valeur Mesur\u00e9e': [\n",
                "        '60-90 ms',\n",
                "        '240-280 ms',\n",
                "        '300-370 ms',\n",
                "        '~800 MB',\n",
                "        '40-60%',\n",
                "        '45-55\u00b0C',\n",
                "        '8-12 W',\n",
                "        '81.87%'\n",
                "    ],\n",
                "    'Cible': [\n",
                "        '-',\n",
                "        '<500 ms',\n",
                "        '<500 ms',\n",
                "        '<2 GB',\n",
                "        '-',\n",
                "        '<70\u00b0C',\n",
                "        '<15 W',\n",
                "        '\u226580%'\n",
                "    ],\n",
                "    'Statut': [\n",
                "        '\u2705 Bon',\n",
                "        '\u2705 Excellent',\n",
                "        '\u2705 Excellent',\n",
                "        '\u2705 Excellent',\n",
                "        '\u2705 Stable',\n",
                "        '\u2705 Optimal',\n",
                "        '\u2705 Efficace',\n",
                "        '\u2705 Cible atteinte'\n",
                "    ]\n",
                "})\n",
                "print(perf_df.to_string(index=False))\n",
                "print(\"=\" * 70)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-comparison-title",
            "metadata": {},
            "source": [
                "## 6. Comparaison PC vs Raspberry Pi 5\n",
                "\n",
                "### 6.1 Comparaison D\u00e9taill\u00e9e\n",
                "\n",
                "| Aspect | PC (GPU) | PC (CPU) | Raspberry Pi 5 (INT8) |\n",
                "|--------|----------|----------|-----------------------|\n",
                "| **Latence Inf\u00e9rence** | 50-80 ms | 200-300 ms | 240-280 ms |\n",
                "| **Mod\u00e8le** | PyTorch FP32 | ONNX FP32 | ONNX INT8 |\n",
                "| **Taille Mod\u00e8le** | 424 MB | 424 MB | 106 MB |\n",
                "| **M\u00e9moire** | 2-3 GB | 1.5-2 GB | ~800 MB |\n",
                "| **Consommation** | 150-300 W | 50-100 W | 8-12 W |\n",
                "| **Co\u00fbt** | 500-2000\u20ac | 400-1000\u20ac | ~80-120\u20ac |\n",
                "| **Portabilit\u00e9** | \u274c Non | \u26a0\ufe0f Limit\u00e9e | \u2705 Excellente |\n",
                "| **Temps R\u00e9el** | \u2705 Oui | \u2705 Oui | \u2705 Oui |\n",
                "\n",
                "### 6.2 Avantages Raspberry Pi 5\n",
                "\n",
                "1. **Efficacit\u00e9 \u00c9nerg\u00e9tique** : 10-25\u00d7 moins de consommation\n",
                "2. **Co\u00fbt** : 5-20\u00d7 moins cher\n",
                "3. **Portabilit\u00e9** : Compact, peut fonctionner sur batterie\n",
                "4. **Fiabilit\u00e9** : Pas de pi\u00e8ces mobiles (avec refroidissement passif)\n",
                "5. **Latence** : Proche du PC CPU (~260 ms vs ~250 ms)\n",
                "\n",
                "### 6.3 Cas d'Usage Recommand\u00e9s\n",
                "\n",
                "| Plateforme | Cas d'Usage Id\u00e9al |\n",
                "|------------|-------------------|\n",
                "| **PC GPU** | Entra\u00eenement, d\u00e9veloppement, inf\u00e9rence batch |\n",
                "| **PC CPU** | Tests, validation, prototypage |\n",
                "| **Raspberry Pi 5** | **D\u00e9ploiement terrain, edge computing, syst\u00e8mes embarqu\u00e9s** |\n",
                "\n",
                "**Conclusion** : Le Raspberry Pi 5 offre un compromis optimal entre **performance**, **co\u00fbt** et **portabilit\u00e9** pour le d\u00e9ploiement du syst\u00e8me SereneSense.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-troubleshooting-title",
            "metadata": {},
            "source": [
                "## 7. D\u00e9pannage et Optimisations\n",
                "\n",
                "### 7.1 Probl\u00e8mes Courants\n",
                "\n",
                "#### Probl\u00e8me 1 : PyAudio ne s'installe pas\n",
                "\n",
                "**Sympt\u00f4me** :\n",
                "```\n",
                "ERROR: Failed building wheel for pyaudio\n",
                "```\n",
                "\n",
                "**Solution** :\n",
                "```bash\n",
                "sudo apt-get install python3-pyaudio portaudio19-dev\n",
                "pip3 install pyaudio\n",
                "```\n",
                "\n",
                "#### Probl\u00e8me 2 : Aucun p\u00e9riph\u00e9rique audio d\u00e9tect\u00e9\n",
                "\n",
                "**Sympt\u00f4me** :\n",
                "```\n",
                "IOError: No Default Input Device Available\n",
                "```\n",
                "\n",
                "**Solution** :\n",
                "```bash\n",
                "# V\u00e9rifier d\u00e9tection\n",
                "lsusb\n",
                "arecord -l\n",
                "\n",
                "# Ajouter l'utilisateur au groupe audio\n",
                "sudo usermod -a -G audio $USER\n",
                "# Puis se d\u00e9connecter et reconnecter\n",
                "```\n",
                "\n",
                "#### Probl\u00e8me 3 : Latence \u00e9lev\u00e9e (>1000 ms)\n",
                "\n",
                "**Causes possibles** :\n",
                "- Throttling thermique (CPU surchauffe)\n",
                "- Alimentation insuffisante\n",
                "- Processus en arri\u00e8re-plan\n",
                "\n",
                "**Solutions** :\n",
                "```bash\n",
                "# V\u00e9rifier temp\u00e9rature\n",
                "vcgencmd measure_temp\n",
                "\n",
                "# V\u00e9rifier throttling\n",
                "vcgencmd get_throttled\n",
                "# 0x0 = pas de throttling\n",
                "\n",
                "# Activer ventilateur (si disponible)\n",
                "sudo raspi-config\n",
                "# Performance Options \u2192 Fan\n",
                "\n",
                "# Mode performance CPU\n",
                "sudo cpufreq-set -g performance\n",
                "```\n",
                "\n",
                "#### Probl\u00e8me 4 : Erreur m\u00e9moire\n",
                "\n",
                "**Sympt\u00f4me** :\n",
                "```\n",
                "MemoryError: Unable to allocate array\n",
                "```\n",
                "\n",
                "**Solution** :\n",
                "```bash\n",
                "# Activer/augmenter swap\n",
                "sudo nano /etc/dphys-swapfile\n",
                "# D\u00e9finir CONF_SWAPSIZE=2048\n",
                "sudo dphys-swapfile setup\n",
                "sudo systemctl restart dphys-swapfile\n",
                "```\n",
                "\n",
                "### 7.2 Optimisations\n",
                "\n",
                "#### Optimisation 1 : Mode Headless (Sans Bureau)\n",
                "\n",
                "\u00c9conomise ~200 MB de RAM et 10-20% de CPU :\n",
                "\n",
                "```bash\n",
                "sudo raspi-config\n",
                "# System Options \u2192 Boot / Auto Login \u2192 Console\n",
                "sudo reboot\n",
                "```\n",
                "\n",
                "#### Optimisation 2 : Service Systemd (D\u00e9marrage Automatique)\n",
                "\n",
                "Cr\u00e9er `/etc/systemd/system/serenity.service` :\n",
                "\n",
                "```ini\n",
                "[Unit]\n",
                "Description=SereneSense Military Vehicle Detector\n",
                "After=network.target sound.target\n",
                "\n",
                "[Service]\n",
                "Type=simple\n",
                "User=pi\n",
                "WorkingDirectory=/home/pi/serenity_deploy\n",
                "ExecStart=/usr/bin/python3 rpi_deploy.py --mode realtime --verbose\n",
                "Restart=on-failure\n",
                "RestartSec=10\n",
                "\n",
                "[Install]\n",
                "WantedBy=multi-user.target\n",
                "```\n",
                "\n",
                "Activer :\n",
                "\n",
                "```bash\n",
                "sudo systemctl enable serenity.service\n",
                "sudo systemctl start serenity.service\n",
                "sudo systemctl status serenity.service\n",
                "\n",
                "# Voir les logs\n",
                "sudo journalctl -u serenity.service -f\n",
                "```\n",
                "\n",
                "#### Optimisation 3 : Surveillance Syst\u00e8me\n",
                "\n",
                "Script de monitoring continu :\n",
                "\n",
                "```bash\n",
                "while true; do\n",
                "    echo \"$(date) | Temp: $(vcgencmd measure_temp) | CPU: $(top -bn1 | grep 'Cpu(s)' | awk '{print $2}')\" | tee -a system_monitor.log\n",
                "    sleep 60\n",
                "done\n",
                "```\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-conclusion-title",
            "metadata": {},
            "source": [
                "## 8. Conclusion et Perspectives\n",
                "\n",
                "### 8.1 Bilan du D\u00e9ploiement\n",
                "\n",
                "Ce notebook a document\u00e9 le **pipeline complet de d\u00e9ploiement** du mod\u00e8le AudioMAE sur Raspberry Pi 5, couvrant :\n",
                "\n",
                "\u2705 **Export ONNX** : PyTorch \u2192 ONNX FP32 (424 MB)  \n",
                "\u2705 **Quantification INT8** : ONNX FP32 \u2192 INT8 (106 MB, 4\u00d7 plus petit)  \n",
                "\u2705 **Validation** : Tests de coh\u00e9rence et performance  \n",
                "\u2705 **Scripts de d\u00e9ploiement** : `rpi_preprocessing.py`, `rpi_deploy.py`  \n",
                "\u2705 **M\u00e9triques de performance** : 82% pr\u00e9cision, <370 ms latence, <800 MB m\u00e9moire  \n",
                "\n",
                "### 8.2 Performances Atteintes\n",
                "\n",
                "| Crit\u00e8re | Objectif | R\u00e9sultat | Statut |\n",
                "|---------|----------|----------|--------|\n",
                "| **Pr\u00e9cision** | \u226580% | 81.87% | \u2705 **Atteint** |\n",
                "| **Latence totale** | <500 ms | 300-370 ms | \u2705 **D\u00e9pass\u00e9** |\n",
                "| **M\u00e9moire** | <2 GB | ~800 MB | \u2705 **D\u00e9pass\u00e9** |\n",
                "| **Consommation** | <15 W | 8-12 W | \u2705 **D\u00e9pass\u00e9** |\n",
                "| **R\u00e9duction taille** | >3\u00d7 | 4.0\u00d7 | \u2705 **D\u00e9pass\u00e9** |\n",
                "\n",
                "**Bilan** : Tous les objectifs de d\u00e9ploiement sont atteints ou d\u00e9pass\u00e9s. Le syst\u00e8me est **pr\u00eat pour la production**.\n",
                "\n",
                "### 8.3 R\u00e9capitulatif des 5 Notebooks\n",
                "\n",
                "Ce projet complet est document\u00e9 \u00e0 travers 5 notebooks Jupyter :\n",
                "\n",
                "1. **Notebook 1** : Pr\u00e9traitement et visualisation MAD  \n",
                "   - 7,466 \u00e9chantillons, 7 classes  \n",
                "   - MFCC (40 coefs) + Mel spectrogrammes (128\u00d7128)  \n",
                "   - HDF5 storage (~2.8 GB)\n",
                "\n",
                "2. **Notebook 2** : Entra\u00eenement CNN-MFCC  \n",
                "   - 242K param\u00e8tres, 3 couches Conv2D  \n",
                "   - Pr\u00e9cision : 66.88% (meilleure), 57.95% (finale)  \n",
                "   - Overfitting s\u00e9v\u00e8re d\u00e9tect\u00e9\n",
                "\n",
                "3. **Notebook 3** : Entra\u00eenement CRNN-MFCC  \n",
                "   - 1.5M param\u00e8tres, 3 Conv2D + 2 BiLSTM  \n",
                "   - Pr\u00e9cision : 73.21% (meilleure), 72.32% (finale)  \n",
                "   - Mod\u00e9lisation temporelle efficace\n",
                "\n",
                "4. **Notebook 4** : Entra\u00eenement AudioMAE  \n",
                "   - 111M param\u00e8tres, Vision Transformer (12 couches)  \n",
                "   - **Pr\u00e9cision : 82.15%** (meilleure du projet)  \n",
                "   - G\u00e9n\u00e9ralisation exceptionnelle (+12.38%)\n",
                "\n",
                "5. **Notebook 5** (ce notebook) : D\u00e9ploiement Raspberry Pi 5  \n",
                "   - ONNX INT8 (106 MB)  \n",
                "   - Latence : 300-370 ms  \n",
                "   - Pr\u00e9cision maintenue : 81.87%\n",
                "\n",
                "### 8.4 Am\u00e9liorations Futures\n",
                "\n",
                "#### Court Terme\n",
                "\n",
                "1. **Tests en conditions r\u00e9elles**  \n",
                "   - Collecter audio de v\u00e9hicules militaires r\u00e9els  \n",
                "   - Valider sur environnements bruyants  \n",
                "   - Ajuster seuils de confiance\n",
                "\n",
                "2. **Int\u00e9grations syst\u00e8me**  \n",
                "   - Indicateurs LED (d\u00e9tection active)  \n",
                "   - Notifications r\u00e9seau (MQTT, HTTP)  \n",
                "   - Enregistrement audio sur d\u00e9tection  \n",
                "   - Dashboard web temps r\u00e9el\n",
                "\n",
                "3. **Optimisations suppl\u00e9mentaires**  \n",
                "   - Quantization-Aware Training (QAT)  \n",
                "   - Profilage du pr\u00e9traitement  \n",
                "   - Multi-threading capture audio\n",
                "\n",
                "#### Moyen Terme\n",
                "\n",
                "1. **Pr\u00e9-entra\u00eenement AudioMAE**  \n",
                "   - Corpus large (AudioSet, FSD50K)  \n",
                "   - 800-1000 epochs masquage  \n",
                "   - Fine-tuning sur MAD  \n",
                "   - **Pr\u00e9cision attendue : 85-90%**\n",
                "\n",
                "2. **M\u00e9thodes d'ensemble**  \n",
                "   - Entra\u00eener 3-5 mod\u00e8les (seeds diff\u00e9rents)  \n",
                "   - Moyenne/vote des pr\u00e9dictions  \n",
                "   - **Gain attendu : +2-4%**\n",
                "\n",
                "3. **D\u00e9ploiement terrain**  \n",
                "   - Bo\u00eetier \u00e9tanche  \n",
                "   - Alimentation batterie  \n",
                "   - Monitoring distant  \n",
                "   - Application mobile\n",
                "\n",
                "#### Long Terme\n",
                "\n",
                "1. **Extension capacit\u00e9s**  \n",
                "   - Localisation audio (source direction)  \n",
                "   - Tracking multi-v\u00e9hicules  \n",
                "   - Reconnaissance mod\u00e8les sp\u00e9cifiques\n",
                "\n",
                "2. **Int\u00e9gration multi-capteurs**  \n",
                "   - Fusion audio + vision (cam\u00e9ra)  \n",
                "   - Int\u00e9gration radar/lidar  \n",
                "   - Syst\u00e8me multi-modal complet\n",
                "\n",
                "### 8.5 Ressources Additionnelles\n",
                "\n",
                "#### Documentation Compl\u00e8te\n",
                "\n",
                "- **Guide de d\u00e9ploiement** : `docs/RPi5_DEPLOYMENT_GUIDE.md` (300+ lignes)\n",
                "- **Quick Start** : `QUICKSTART_DEPLOYMENT.md` (d\u00e9ploiement en 30 min)\n",
                "- **R\u00e9sultats finaux** : `docs/reports/FINAL_RESULTS.md`\n",
                "- **R\u00e9sum\u00e9 d\u00e9ploiement** : `DEPLOYMENT_SUMMARY.md`\n",
                "\n",
                "#### Scripts Essentiels\n",
                "\n",
                "```\n",
                "scripts/\n",
                "\u251c\u2500\u2500 export_to_onnx.py          # Export PyTorch \u2192 ONNX\n",
                "\u251c\u2500\u2500 quantize_onnx.py           # Quantification INT8\n",
                "\u251c\u2500\u2500 test_deployment.py         # Validation pipeline\n",
                "\u251c\u2500\u2500 rpi_preprocessing.py       # Pr\u00e9traitement RPi\n",
                "\u251c\u2500\u2500 rpi_deploy.py              # Application d\u00e9ploiement\n",
                "\u251c\u2500\u2500 rpi_requirements.txt       # D\u00e9pendances Python\n",
                "\u2514\u2500\u2500 rpi_setup.sh               # Setup automatique\n",
                "```\n",
                "\n",
                "#### Support et Contact\n",
                "\n",
                "Pour questions ou probl\u00e8mes :\n",
                "1. Consulter `docs/RPi5_DEPLOYMENT_GUIDE.md` (section Troubleshooting)\n",
                "2. V\u00e9rifier `QUICKSTART_DEPLOYMENT.md` (solutions communes)\n",
                "3. Examiner docstrings des scripts\n",
                "\n",
                "---\n",
                "\n",
                "## Fin du Notebook 5\n",
                "\n",
                "**Projet SereneSense** : Pipeline complet de bout en bout  \n",
                "**Du t\u00e9l\u00e9chargement des donn\u00e9es** (MAD dataset)  \n",
                "**Au d\u00e9ploiement edge** (Raspberry Pi 5)  \n",
                "**En passant par** le pr\u00e9traitement, l'entra\u00eenement (CNN, CRNN, AudioMAE), et l'optimisation\n",
                "\n",
                "**Status final** : \u2705 **Syst\u00e8me op\u00e9rationnel et pr\u00eat pour la production**\n",
                "\n",
                "---\n",
                "\n",
                "*Notebook cr\u00e9\u00e9 le : 2025-11-21*  \n",
                "*Projet : SereneSense - D\u00e9tection V\u00e9hicules Militaires*  \n",
                "*Mod\u00e8le : AudioMAE (Vision Transformer)*  \n",
                "*Pr\u00e9cision finale : 82.15% (entra\u00eenement) / 81.87% (d\u00e9ploiement)*\n",
                "\n",
                "---"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
