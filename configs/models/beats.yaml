# BEATs (Bidirectional Encoder representation from Audio Transformers) Configuration
# Based on BEATs paper: https://arxiv.org/abs/2212.09058
# Optimized for military vehicle sound detection

model:
  name: "BEATs"
  type: "bidirectional_audio_transformer"
  version: "1.0"
  
  # Architecture Configuration
  architecture:
    # Acoustic Tokenizer Configuration
    tokenizer:
      # Conv1D feature extractor
      conv_layers:
        - [512, 10, 5]                # [out_channels, kernel_size, stride]
        - [512, 3, 2]
        - [512, 3, 2]
        - [512, 3, 2]
        - [512, 3, 2]
        - [512, 2, 2]
        - [512, 2, 2]
      
      # Feature projection
      feature_grad_mult: 1.0          # Gradient multiplier for features
      
      # Quantization for discrete tokens
      quantizer:
        enabled: true                 # Enable vector quantization
        codebook_size: 8192           # Size of quantization codebook
        latent_dim: 768               # Latent dimension
        commitment_cost: 0.25         # Commitment loss weight
        
      # Normalization
      layer_norm_first: false         # Apply layer norm before conv
      
    # Transformer Encoder Configuration  
    encoder:
      # Architecture
      embed_dim: 768                  # Model dimension
      ffn_embed_dim: 3072            # Feed-forward dimension
      layers: 12                      # Number of transformer layers
      attention_heads: 12             # Number of attention heads
      
      # Normalization and activation
      normalize_before: false         # Pre-norm vs post-norm
      activation_fn: "gelu"           # Activation function
      dropout: 0.1                    # General dropout rate
      attention_dropout: 0.1          # Attention dropout rate
      activation_dropout: 0.0         # Activation dropout rate
      
      # Positional encoding
      learned_pos: true               # Use learned positional embeddings
      conv_pos: 128                   # Convolutional positional encoding
      conv_pos_groups: 16             # Number of groups for conv pos
      
    # Pre-training Head Configuration
    pretraining_head:
      # Masked prediction
      mask_prob: 0.65                 # Probability of masking a token
      mask_length: 10                 # Average mask length
      mask_selection: "static"        # static, uniform, normal, poisson
      mask_other: 0.0                 # Probability of masking unmasked tokens
      no_mask_overlap: false          # Prevent mask overlap
      
      # Target generation
      target_glu: true                # Use GLU in target network
      target_layers: 12               # Target network depth
      
    # Classification Head Configuration
    classification_head:
      num_classes: 7                  # MAD dataset classes
      pooler_dropout: 0.1             # Pooler dropout rate
      pooler_activation_fn: "tanh"    # Pooler activation
      classifier_dropout: 0.0         # Final classifier dropout
      
  # Audio Processing Configuration
  audio:
    # Input specifications
    sample_rate: 16000                # Target sample rate
    normalize: true                   # Normalize input audio
    
    # Preprocessing
    preprocessing:
      # Waveform preprocessing
      preemphasis: 0.97               # Pre-emphasis coefficient
      
      # Normalization
      normalize_type: "utterance"     # utterance, global, none
      subtract_mean: true             # Subtract utterance mean
      
      # Dynamic range
      max_sample_size: 320000         # Maximum sample size (20s at 16kHz)
      min_sample_size: 32000          # Minimum sample size (2s at 16kHz)
      
  # Tokenization Configuration
  tokenization:
    # Vector Quantization
    vq:
      # Codebook configuration
      num_vars: 320                   # Number of codebook variables
      temp: [2.0, 0.5, 0.999995]     # Temperature scheduling [start, end, decay]
      
      # Groups and diversity
      num_groups: 2                   # Number of codebook groups
      combine_groups: false           # Combine group representations
      
      # Training dynamics
      vq_dim: 256                     # VQ dimension
      time_first: true                # Time-first representation
      
    # Gumbel softmax (alternative to VQ)
    gumbel:
      enabled: false                  # Use Gumbel softmax instead of VQ
      hard: true                      # Hard Gumbel softmax
      
  # Pre-training Configuration
  pretraining:
    # Self-supervised objectives
    objectives:
      # Masked language modeling
      mlm:
        enabled: true                 # Enable masked token prediction
        weight: 1.0                   # Loss weight
        
      # Contrastive learning
      contrastive:
        enabled: false                # Enable contrastive learning
        weight: 0.1                   # Contrastive loss weight
        temperature: 0.1              # Temperature for contrastive loss
        
    # Teacher-student framework
    teacher_student:
      enabled: false                  # Enable teacher-student learning
      teacher_model: null             # Path to teacher model
      distillation_weight: 0.5        # Distillation loss weight
      temperature: 4.0                # Distillation temperature

# Training Configuration
training:
  # Optimizer configuration
  optimizer:
    type: "AdamW"
    lr: 2e-4                         # Base learning rate
    weight_decay: 0.01               # Weight decay
    betas: [0.9, 0.98]              # Adam betas
    eps: 1e-6                       # Epsilon
    
  # Learning rate scheduler
  lr_scheduler:
    type: "polynomial_decay"
    power: 1.0                      # Polynomial power
    warmup_updates: 10000           # Warmup steps
    total_updates: 100000           # Total training steps
    
  # Loss configuration
  loss:
    # Pre-training losses
    pretraining:
      target_loss_weight: 1.0       # Target prediction loss weight
      diversity_loss_weight: 0.1    # Diversity loss weight
      
    # Fine-tuning loss
    finetuning:
      type: "cross_entropy"         # Classification loss
      label_smoothing: 0.1          # Label smoothing
      
  # Training dynamics
  dynamics:
    # Gradient clipping
    clip_norm: 10.0                 # Gradient norm clipping
    
    # Update frequency
    update_freq: [1]                # Gradient accumulation steps
    
    # Skip updates
    skip_invalid_size_inputs_valid_test: true
    
# Data Configuration
data:
  # Batch configuration
  batch:
    max_tokens: 1400000             # Maximum tokens per batch
    required_batch_size_multiple: 1 # Batch size multiple
    
  # Sampling
  sampling:
    shuffle: true                   # Shuffle training data
    distributed_world_size: 1       # World size for distributed training
    
# Regularization
regularization:
  # Dropout scheduling
  dropout_schedule:
    enabled: false                  # Enable dropout scheduling
    start_dropout: 0.1              # Starting dropout rate
    end_dropout: 0.0                # Ending dropout rate
    
  # Stochastic depth
  stochastic_depth:
    enabled: true                   # Enable stochastic depth
    drop_path_rate: 0.1             # Drop path rate
    
  # Layer-wise learning rate decay
  layer_decay:
    enabled: false                  # Enable layer-wise LR decay
    decay_rate: 0.75                # Decay rate per layer

# Hardware Configuration
hardware:
  # Device configuration
  device: "auto"                    # auto, cuda, cpu
  fp16: true                        # Enable mixed precision
  
  # Memory optimization
  memory:
    empty_cache_freq: 0             # Empty cache frequency (0=disabled)
    
  # Distributed training
  distributed:
    backend: "nccl"                 # Distributed backend
    
# Monitoring Configuration
monitoring:
  # Logging
  logging:
    log_interval: 100               # Log every N updates
    log_format: "simple"            # Log format
    
  # Validation
  validation:
    valid_subset: "valid"           # Validation subset name
    validate_interval: 1            # Validate every N epochs
    validate_interval_updates: 0    # Validate every N updates
    
  # Checkpointing
  checkpointing:
    save_interval: 1                # Save every N epochs
    save_interval_updates: 0        # Save every N updates
    keep_interval_updates: -1       # Keep every N updates
    keep_last_epochs: 5             # Keep last N epoch checkpoints
    
  # Early stopping
  early_stopping:
    patience: 10                    # Early stopping patience
    min_delta: 0.001                # Minimum change threshold
    
# Inference Configuration
inference:
  # Beam search (for generative tasks)
  beam_search:
    beam_size: 1                    # Beam size for inference
    max_len_a: 0                    # Maximum length coefficient a
    max_len_b: 200                  # Maximum length coefficient b
    
  # Post-processing
  post_processing:
    normalize_scores: true          # Normalize prediction scores
    
# Model Export Configuration
export:
  # Supported formats
  formats:
    pytorch: true                   # Export PyTorch model
    onnx: true                      # Export ONNX model
    torchscript: false              # Export TorchScript (not recommended for BEATs)
    
  # Optimization
  optimization:
    # Quantization
    quantization:
      enabled: false                # Enable quantization
      method: "dynamic"             # dynamic, static
      
    # Pruning
    pruning:
      enabled: false                # Enable model pruning
      sparsity: 0.1                 # Target sparsity
      
# Edge Deployment Configuration
edge_deployment:
  # Target platforms
  platforms:
    jetson:
      enabled: true                 # Enable Jetson deployment
      precision: "fp16"             # fp16, fp32, int8
      max_batch_size: 1             # Maximum batch size
      
    raspberry_pi:
      enabled: true                 # Enable RPi deployment
      precision: "fp32"             # fp32, int8
      optimization_level: "O2"      # Optimization level
      
  # Performance targets
  performance:
    max_latency_ms: 50              # Maximum inference latency
    min_throughput_fps: 20          # Minimum throughput
    max_memory_mb: 1024             # Maximum memory usage
    
# Model Variants
variants:
  # Model size variants
  base:
    embed_dim: 768
    layers: 12
    attention_heads: 12
    
  large:
    embed_dim: 1024
    layers: 24
    attention_heads: 16
    
  small:
    embed_dim: 512
    layers: 6
    attention_heads: 8
    
# Dataset-specific Configuration
dataset_specific:
  # MAD dataset optimization
  mad:
    # Class-specific processing
    helicopter:
      boost_factor: 1.2             # Boost factor for helicopter samples
    fighter_aircraft:
      boost_factor: 1.1             # Boost factor for fighter aircraft
      
  # AudioSet pre-training
  audioset:
    # Subset configuration
    subset_classes: null            # Use all classes (null) or specify subset
    sample_rate_adaptation: true    # Adapt to different sample rates